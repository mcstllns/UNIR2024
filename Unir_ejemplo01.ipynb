{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCiIzsnoZLppy3kQELqC5F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcstllns/UNIR2024/blob/main/Unir_ejemplo01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bienvenido a colab\n",
        "\n",
        "En este cuaderno vamos a construir nuestras primeras redes neuronales, vete fijándote en el código y en las explicaciones que se adjuntan porque luego tendrás que hacer un ejercicio en moodle.\n",
        "\n",
        "Vamos a empezar por las redes más asequibles, los __perceptrones multicapa__, exactamente iguales que los que hemos estado utilizando en [playground](https://playground.tensorflow.org/).\n",
        "\n",
        "La tarea es identica a la realizada en playground pero ahora en vez de ser un sandbox completamente opaco vamos a programar nuestras redes.\n",
        "\n",
        "__No te frustres__, a veces escribir código es frustrante porque te da la sensación de que unas veces funciona y otras no. Los ordenadores son deterministas, no tienen opiniones ni les caes mal; si antes te ha funcionado y ahora no es porque hay algo diferente, sigue intentándolo y si ves que no lo consigues consulta con un compañero o con el profesor.\n",
        "\n",
        "En general, los ejercicios siempre están basados en cosas que han sido explicadas, cuando haya un ejercicio que no te salga, relee los materiales y fíjate despacio en el código previo, es posible que la solución la tengas a la vista. Si aún así no encuentras la solución pregunta a tus compañeros y __no dudes en contactar conmigo__.\n"
      ],
      "metadata": {
        "id": "xaONo1fblwXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 01. Regresión con datos de felicidad\n",
        "\n",
        "Se analizan unos datos obtenido de Kaggle.com sobre la encuesta de felicidad de 2021: [enlace](https://www.kaggle.com/datasets/ajaypalsinghlo/world-happiness-report-2021)\n",
        "\n",
        "Una vez limpiados y preparados la base de datos consta de 9 variables predictoras y una variable criterio:\n",
        "\n",
        "**Criterio**: Life.Ladder.\n",
        "\n",
        "**Predictoras**: year, Log.GDP.per.capita, Social.support,\tHealthy.life.expectancy.at.birth, Freedom.to.make.life.choices,\tGenerosity,\tPerceptions.of.corruption,\tPositive.affect,\tNegative.affect.\n",
        "\n",
        "El mejor modelo calculado con estadística convencional (modelo lineal) da un **MSE de 0.235**\n",
        "\n"
      ],
      "metadata": {
        "id": "glXJNUn_kS-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero que vamos a hacer es cargar un montón de paquetes y librerías de python que vamos a necesitar para que se calculen las redes. No te preocupes por esta parte, no es necesario entender qué o cómo lo hace, simplemente ejecútala. Lo que hace este código es:\n",
        "\n",
        "Carga los paquetes: numpy, tensorflow2, panda, matplolib, keras y sklearn. Son paquetes básicos para el trabajo con datos y los paquetes relacionados con Deep Learning.\n",
        "\n",
        "Construímos una función llamada plot_history que nos va a servir para visualizar el progreso en el aprendizaje de la red\n",
        "\n",
        "\n",
        "Para ejecutar un código puedes pinchar en la flecha de la celda o usar Ctr+Enter en el teclado."
      ],
      "metadata": {
        "id": "zjk8bK3xknUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paquetes y librerías que vamos a necesitar\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "e37njN0hnxkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos algunas funciones que vamos a necesitar\n",
        "\n",
        "# hace un plot de la historia de ajuste\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error')\n",
        "  plt.plot(hist['epoch'], hist['mse'],'r--',\n",
        "           label='Training Error')\n",
        "  # plt.plot(hist['epoch'], hist['val_mse'],'b',\n",
        "  #          label = 'Validation Error')\n",
        "  plt.ylim([0,0.5])\n",
        "  plt.axhline(y=0.235, color='b', linestyle='-')\n",
        "  plt.legend()\n",
        "  plt.show() # un €\n",
        "\n",
        "# normaliza un conjunto de datos\n",
        "def norm(x, st):\n",
        "    return((x - st['mean'])/st['std'])"
      ],
      "metadata": {
        "id": "7CBNXEnVoWb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4R9WmGzlvtK"
      },
      "outputs": [],
      "source": [
        "# Cargamos los datos desde mi Github (mcstllns/UNIR2024)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/mcstllns/UNIR2024/main/data-happiness.csv'\n",
        "data  = pd.read_csv(url)\n",
        "print(data.keys())\n",
        "data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# El fichero tiene datos perdidos y hay que eliminar las filas\n",
        "data = data.dropna()\n"
      ],
      "metadata": {
        "id": "k1hmMDUwofFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos los dos conjuntos de datos x son los datos de entrada (variables predictoras) e y es la variable criterio (Ladder)\n",
        "\n",
        "x = data.drop('Life.Ladder', axis=1)\n",
        "y = data['Life.Ladder']\n",
        "\n",
        "print(x.head())\n",
        "print(y.head())"
      ],
      "metadata": {
        "id": "muN2PURt5NE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos la red neuronal, para construirla se siguen los siguientes pasos:\n",
        "\n",
        "1. Definimos la estructura del modelo con el numero de capas y neuronas que deseemos\n",
        "1. Compilamos el modelo definiendo la función de pérdida, el algoritmo de aprendizaje y la métrica del ajuste\n",
        "1.  Iniciamos el ajuste del modelo definiendo el número de épocas (iteraciones) que vamos a calcular"
      ],
      "metadata": {
        "id": "LL5oNVSklTqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo --------------------------\n",
        "\n",
        "\n",
        "# Configuramos la topología\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(len(x.keys()),)))\n",
        "model.add(Dense(4, activation = 'relu'))\n",
        "# model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "# summarize layers\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "Gd5yPNoSonnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizamos x para un mejor rendimiento\n",
        "\n",
        "# x_stats = x.describe().transpose()\n",
        "# x_norm = norm(x, x_stats)\n",
        "# x_norm.describe().transpose()"
      ],
      "metadata": {
        "id": "DV2mkt1YvXYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo, definimos los hiperparámetros\n",
        "#  - Función de pérdida: mse\n",
        "#  - Algoritmo de aprendizaje: Adam con lr = 0.001\n",
        "#  - Métricas: mse\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              metrics = ['mse'])"
      ],
      "metadata": {
        "id": "eIWMIwiYtSRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x, y,\n",
        "                    # x_norm, y,\n",
        "                    epochs = 200,\n",
        "                    verbose = 1\n",
        "                    ) # para evitar que se llene toda la pantalla"
      ],
      "metadata": {
        "id": "AiPxFI9ctYTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el modelo con el conjunto de validacion\n",
        "model.evaluate(x,\n",
        "               # x_norm,\n",
        "               y)"
      ],
      "metadata": {
        "id": "wUZjOkQOu9Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "bhoZnZYCtxbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}